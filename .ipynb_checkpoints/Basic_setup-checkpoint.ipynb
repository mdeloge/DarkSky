{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import urllib2\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "import json \n",
    "import ConfigParser\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable config\n",
    "###### api_key\n",
    "The key used to authenticate with the DarkSky API, get your own at darksky.net/dev\n",
    "###### Longitude/Latitude\n",
    "Geopy derived geographical information from your specified location\n",
    "###### base_url\n",
    "The base url used for GET request to the DarkSky API, containing your api_key and location information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = ConfigParser.RawConfigParser()\n",
    "config.read('synchronization.cfg')\n",
    "api_key = config.get('Darksky', 'api_key')\n",
    "\n",
    "geolocator = Nominatim()\n",
    "location = geolocator.geocode('Muntstraat 10 Leuven')\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "\n",
    "base_url = config.get('Darksky', 'base_url') + api_key \\\n",
    "        + '/' + str(latitude) + ',' + str(longitude) + ','"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL builder\n",
    "Using this function a list is made that can later be iterated over to fetch a large amount of weather data in a fixed date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def url_builder(start_date, end_date=dt.datetime.now()):\n",
    "    url_list = []\n",
    "    delta = end_date - start_date\n",
    "    for counter in range(delta.days):\n",
    "        timestamp = str(time.mktime((start_date + dt.timedelta(days=counter)).timetuple()))[:-2]\n",
    "        if os.path.isfile('local_data/full_data_' + timestamp + '.json'):\n",
    "            continue\n",
    "        full_url = base_url + timestamp\n",
    "        url_list.append(full_url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_list = url_builder(dt.datetime(2017,6,12))\n",
    "len(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fahrenheit to Celsius\n",
    "Because everyone likes non retard units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_t_c(fahrenheit):\n",
    "    return (((fahrenheit - 32) * 5.0) / 9.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch JSON data from URL\n",
    "JSON data is locally stored so all future code can use the locally stored files and don't require any remote API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_and_store_json(url):\n",
    "    try:\n",
    "        request = requests.get(url=url, timeout=10)\n",
    "    except ReadTimeout as t:\n",
    "        print \"Read timeout\"\n",
    "        request = None\n",
    "    if request is None:\n",
    "        while(request is None):\n",
    "            request = requests.get(url=url, timeout=1)\n",
    "    content = json.loads(request.content)\n",
    "    storage = open('local_data/full_data_' + url.split(',')[2] + '.json', 'w')    \n",
    "    #storage.write(json.dumps(content))  #for BigQuery ready json file\n",
    "    storage.write(json.dumps(content, separators=(',', ': '), indent=5))  #For clean indentation\n",
    "    storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for url in tqdm(url_list):\n",
    "    fetch_and_store_json(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
